---
title: "Exploracion_inicial"
author: "Gabriela Centeno y Sofía Zorrilla"
format: html
knitr:
  opts_knit:
    root.dir: "../../"

---

```{r}
# --- Load libraries ---
library(dplyr)
library(readr)
library(data.table)
library(ggplot2)
library(here)
library(sf)
```

- Subir datos crudos 

```{r} 
#| eval: false

# Load tables from gbif 
files_list <- list.files(here::here("data/in/gbif_dwc/division_occurrence"), pattern=".csv", full.names=TRUE)


files <- lapply(files_list,fread)

recordsGbif_raw <- do.call(rbind,files)

recordsHerbario_raw <- fread(here::here("data/in/herbariomex_dw/occurrences.csv"))

gbif_nombres_backbone <- fread(here::here("data/in/backbone/gbif_nombres_backbone.csv"))

herb_nombres_backbone <- fread(here::here("data/in/backbone/herb_final_backbone.csv"))




```



-   Unir metadatos con la base de datos con los nombres corregidos

```{r}
# --- Generar un id interno para cada tabla
recordsGbif_raw <- recordsGbif_raw %>%
  mutate(id_interno = paste0("GBIF_", row_number()))

recordsHerbario_raw <- recordsHerbario_raw %>%
  mutate(id_interno = paste0("Herb_", row_number()))


# --- Unir columnas del herbario con el herbario corregido 

herb_corr_raw <- cbind(recordsHerbario_raw, herb_nombres_backbone)

# --- Unir columnas de gbif con gbif corregido 

gbif_corr_raw <- cbind(recordsGbif_raw, gbif_nombres_backbone)


```

-   Unir la tabla del herbario y el gbif

```{r}
#Agregar sufijo para que no haya columnas duplicadas
names(herb_corr_raw) <- make.names(names(herb_corr_raw), unique = TRUE)
names(gbif_corr_raw) <- make.names(names(gbif_corr_raw), unique = TRUE)

herb_corr_raw <- herb_corr_raw %>%
  mutate(across(everything(), as.character)) %>% 
  select(scientificName, canonicalName, correctname, rank, decimalLatitude, decimalLongitude, stateProvince, county, municipality,locality, eventDate, year, month, recordedBy, id_interno)

gbif_corr_raw <- gbif_corr_raw %>%
  mutate(across(everything(), as.character)) %>% 
  select(scientificName, canonicalName, correctname, rank, decimalLatitude, decimalLongitude, stateProvince, county, municipality,locality, eventDate, year, month, recordedBy, id_interno)


```



```{r}
# Unir las filas de los data frames
gbif_herb_raw <- bind_rows(herb_corr_raw, gbif_corr_raw)


```


-Ver nombres que no coincidieron con ningun correctname

#TODO: Al final tenemos que decidir que hacer con los registros que no existen en el correctname y si son especies. (Por ejemplo Q. tristis, Q. lanceolata)

```{r}
sin_cn <-  gbif_herb_raw %>%
  filter(is.na(correctname))

table(sin_cn$scientificName) 
```

Filtrar registros a nivel de genero 

```{r}
gbif_herb_raw <- gbif_herb_raw %>% filter(!scientificName %in% c("Quercus","Quercus L."))
```


-   Contar duplicados

-   Coordenadas
    
```{r}
#Eliminar registros sin coordenadas 
gbif_herb_coor <- gbif_herb_raw %>%
  filter(!is.na(decimalLatitude) & !is.na(decimalLongitude))
```

    
-Coordenadas duplicadas
    
```{r}

# Identificar las filas duplicadas basadas en las coordenadas

coor_duplicated <- gbif_herb_coor %>%
  filter(duplicated(cbind(decimalLatitude, decimalLongitude)))

```
  
    
    -   Coordenadas, nombre, localidad (puede haber errores de formato en la escritura de localidad)
```{r}
corr_loc_name_dupli <-  gbif_herb_coor %>%
  filter(duplicated(cbind(decimalLatitude, decimalLongitude, correctname, municipality) , fromLast = TRUE))
```
    
    Estos son 18411 registros.
    
    -   Replicas del mismo individuo (coordenada, nombre de los colectores, fecha de colecta y especie)
    
```{r}
colectors_date_species_replica <-  gbif_herb_coor%>%
  filter(duplicated(cbind(decimalLatitude, decimalLongitude, recordedBy,eventDate,correctname) , fromLast = TRUE)) 

```

    Estos son 14067 registros. 



- Eliminar duplicados 

```{r}
# --- Eliminar por coordenadas, nombre de la especie y localidad

hgbif_no_duplicates <- gbif_herb_coor %>%
  distinct(decimalLatitude, decimalLongitude, correctname, municipality, .keep_all = TRUE)
```

Registros sin duplicados: 56,363

Guardarlo en un csv

```{r}
write.csv(hgbif_no_duplicates, file = here::here("data/out/hgbif_no_duplicates.csv"))
```

- Ver cuantos NA hay 
```{r}
colSums(is.na(hgbif_no_duplicates))

table(hgbif_no_duplicates[is.na(hgbif_no_duplicates$correctname),]$scientificName)

```

    
-   Extraer elevación:

elevatr: Por default los datos se extraen de AW3D30
(INEGI CEM (Continuo de elevacion mexicana) 15m)[https://www.inegi.org.mx/app/geo2/elevacionesmex] 
Crear objeto con el archivo hgbif_no_duplicates.csv para no tener que correr el codigo de arriba
```{r}
hgbif_no_duplicates <- fread(here::here("data/out/hgbif_no_duplicates.csv"))
```


```{r}

#Inicia funcion
library(elevatr)
library(data.table)

#Genera el df de elevacion

# Reordena las columnas de la tabla para que decimalLongitude sea la primera y decimalLatitude la segunda

hgbif_no_duplicates_coor <- hgbif_no_duplicates %>%
  mutate(
    decimalLongitude = as.numeric(decimalLongitude),
    decimalLatitude = as.numeric(decimalLatitude)
  ) %>%
  select(decimalLongitude, decimalLatitude)  %>%
  filter(decimalLongitude >= -180 & decimalLongitude <= 180, decimalLatitude >= -90 & decimalLatitude <= 90)

#Solo hay un registro que se elimina 


# Convertir a objeto sf

library(sf)

hgbif_no_duplicates_sf <- st_as_sf(hgbif_no_duplicates_coor,coords = c("decimalLongitude", "decimalLatitude"), crs = 4326)


# Obtener elevación para cada punto en tu base de datos
elev_data <- get_elev_point(hgbif_no_duplicates_sf, 
                            src = "aws", # Usa Amazon Web Services como fuente de datos de elevación
                            z = 7)      # Nivel de zoom (determina la precisión) 7 parece ser 1 km (https://github.com/tilezen/joerd/blob/master/docs/data-sources.md#what-is-the-ground-resolution)


#guardar en un csv 
write.csv(elev_data, here::here("data/in/elevation/elev_data.csv"))

```

```{r}
##Extraer elevacion a partir del CEM de INEGI

library(terra)
library(sf)

# Set file paths
raster_path <- here::here("data/in/CEM/CEM_15m_ITRF08.tif")  # Path to the large TIFF file
output_csv <- here::here("data/in/elevation/elevation_INEGI.csv")     # Output CSV file

# Load the raster efficiently
raster <- rast(raster_path)


# Ensure CRS matches
if (!st_crs(hgbif_no_duplicates_sf) == crs(raster)) {
  points_sf <- st_transform(hgbif_no_duplicates_sf, crs(raster))
}

# Convert sf object to SpatVector for efficient extraction
points_vect <- vect(points_sf)

# Extract elevation values
extracted_values <- terra::extract(raster, points_vect)

# Merge extracted values with the original sf object
points_sf$elevation <- extracted_values[, 2]  # Assuming first column is ID

# Write to CSV
st_drop_geometry(points_sf) |> 
  write.csv(output_csv, row.names = FALSE)

``` 

```{r}
#Generar el df con las coordenadas correctas y todas las columnas para agregar la columna de elevacion a cada registro
hgbif_no_duplicates_coor_completo <- hgbif_no_duplicates %>%
  mutate(
    decimalLongitude = as.numeric(decimalLongitude),
    decimalLatitude = as.numeric(decimalLatitude)
  ) %>%
  select(decimalLongitude, decimalLatitude,everything())  %>%
  filter(decimalLongitude >= -180 & decimalLongitude <= 180, decimalLatitude >= -90 & decimalLatitude <= 90)

#Agregar columna de elevacion
elev_data_elevatr <- fread(here::here("data/in/elevation/elev_data.csv"))
elev_data_INEGI <- fread(here::here("data/in/elevation/elevation_INEGI.csv"))

hgbif_no_duplicates_coor_completo$elevacion_elevatr <- elev_data_elevatr$elevation
hgbif_no_duplicates_coor_completo$elevacion_INEGI <- elev_data_INEGI$elevation

#guardar en un csv 
write.csv(hgbif_no_duplicates_coor_completo, here::here("data/in/hgbif_no_duplicates_coor_completo.csv"))


#Ver rango de elevacion que hay 
range(hgbif_no_duplicates_coor_completo$elevacion)


# Filtrar los datos para mantener solo las filas donde la elevación sea mayor o igual a cero
hgbif_no_duplicates_elev1 <- hgbif_no_duplicates_coor_completo %>%
  filter(elevacion >= 0)

# Verifica el rango después de eliminar las elevaciones negativas
range(hgbif_no_duplicates_elev1$elevacion)

#Hay 100 registros que aparecen con elevaciones menores a 0

hgbif_no_duplicates_elev0 <- hgbif_no_duplicates_coor_completo %>%
  filter(elevacion < 0)

```


- Obtener estado y municipio por registro 
```{r}
#Subir las capas 
hgbif_no_duplicates_coor_completo <- fread(here::here("data/in/hgbif_no_duplicates_coor_completo.csv"))

mun <- st_read(here::here("data/in/mun22gw/mun22gw.shp"))

# Select only the relevant columns from the sf objects
mun2<- mun[, c("NOMGEO", "NOM_ENT", "geometry")]

points_hgbif <- st_as_sf(hgbif_no_duplicates_coor_completo, coords = c("decimalLongitude", "decimalLatitude"), crs = 4326) 

points_mun_state <- st_join(points_hgbif, mun2)

coordinates <- st_coordinates(points_mun_state)

points_mun_state <- cbind(points_mun_state, coordinates)

hgbif_completo <- as.data.frame(points_mun_state) %>% 
  select(-1, -2, -"stateProvince", -"county",-"municipality") 

write.csv(hgbif_no_duplicates_coor_completo, here::here("data/in/hgbif_completo.csv"))

```

-   Tabla de registros por especie

```{r}
species_count <- hgbif_completo %>%
  count(correctname, name = "total_registros")%>%
  arrange(total_registros)  %>%
  filter(!is.na(correctname))   #Hay 27 NAs

```

-   Histograma de fechas
```{r}

# Load lubridate if not already loaded
library(lubridate)

# Extract the year from eventDate
hgbif_years <- hgbif_completo %>%
  mutate(year = year(ymd(eventDate)))

# Crear un histograma por año
hist_conteos <- ggplot(hgbif_years, aes(x = year)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue", alpha = 0.7) +
  labs(title = "Histograma de Fechas de Colecta (Por Año)",
       x = "Año de Colecta",
       y = "Número de Registros") +
  theme_minimal() +
   scale_x_continuous(limits = c(1827, 2024),
                       breaks = seq(1827, 2024, by = 10))
```


-   Mapa general 

```{r}
library(maps)

# Cargar mapa base de México
mexico_map <- map_data("world", region = "Mexico")

# Graficar
mapa_general <- ggplot() +
  geom_polygon(data = mexico_map, aes(x = long, y = lat, group = group), fill = "lightblue", color = "black") +
  geom_point(data = hgbif_completo, 
             aes(x = X, y = Y), 
             color = "red", size = 3) +
  theme_minimal() +
  labs(title = "Mapa de Puntos", x = "Longitud", y = "Latitud")
```

-Ver puntos que caen el mar 
```{r}
library(rnaturalearth)
library(ggspatial)

# Obtener el mapa de México (o de los países) con rnaturalearth
mexico_map <- ne_countries(scale = "small", returnclass = "sf", country = "Mexico")

# Ver si los puntos están dentro de los límites de los países
puntos_mex <- st_intersects(points_mun_state, mexico_map, sparse = FALSE)

puntos_terrestres <- puntos_sf[apply(puntos_mex, 1, any), ]

# Identificar los puntos que están fuera de México (FALSE)
puntos_fuera <- !apply(puntos_mex, 1, any)

# Mostrar los puntos que están fuera de los límites de México
puntos_fuera_df <- hgbif_completo[puntos_fuera, ]

```


```{r}
library(rnaturalearth)
library(ggspatial)

# Obtener el mapa de México (o de los países) con rnaturalearth
mexico_map <- ne_countries(scale = "small", returnclass = "sf", country = "Mexico")


# Ver si los puntos están dentro de los límites de los países
puntos_mex <- st_intersects(points_mun_state, mexico_map, sparse = FALSE)

# Filtrar los puntos que están dentro de los límites terrestres 
puntos_terrestres <- puntos_sf[apply(puntos_mex, 1, any), ]

# Identificar los puntos que están fuera de México (FALSE)
puntos_fuera <- !apply(puntos_mex, 1, any)

# Mostrar los puntos que están fuera de los límites de México
puntos_fuera_df <- hgbif_completo[puntos_fuera, ]